# ---- Optional extra index for CPU PyTorch wheels (Linux x86_64) ----
--extra-index-url https://download.pytorch.org/whl/cpu

# --- Web API ---
fastapi>=0.110,<1.0
uvicorn[standard]>=0.27

# --- Config / settings ---
pydantic>=2.4
pydantic-settings>=2.2

# --- Async + HTTP ---
httpx>=0.24.1
tenacity>=8.2.3

# --- Redis (async) ---
redis>=5.0.1

# --- Metrics ---
prometheus-client>=0.20.0

# --- Data wrangling + parquet ---
pandas>=2.2.0
numpy>=1.26.0
pyarrow>=15.0.0
fsspec>=2024.6.0
s3fs>=2024.6.1
gcsfs>=2024.6.1
numba>=0.59.0

# --- Exchanges (async CCXT) ---
ccxt>=4.3.0

# --- Scheduler service ---
APScheduler==3.10.4
pytz>=2023.3
tzlocal>=5.2

# --- RSS / News utilities ---
feedparser>=6.0.10

# --- WebSocket support (Starlette pulls this, but keep explicit) ---
websockets>=12.0

# --- ML (sentiment adapter) ---
# NOTE: `torch` wheels vary by platform/arch and the `+cpu` build is not
# universally available (e.g., macOS ARM). Transformers is optional in runtime:
# our adapter gracefully degrades if model load fails. Keep `torch` handled
# by the Dockerfile (Linux) and make it optional here for local installs.
transformers>=4.41.0
# torch is installed in Docker image; uncomment for local Linux if needed
# torch>=2.3,<3

# --- Social APIs ---
tweepy>=4.14.0
ratelimit>=2.2.1

# --- Testing/dev utilities ---
fakeredis>=2.21.0
